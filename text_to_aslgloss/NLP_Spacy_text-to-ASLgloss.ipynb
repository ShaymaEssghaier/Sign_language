{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "##pip install spacy\n",
    "##python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search: rules for glossing in ASL \n",
    "ChatGPT: what are the rules for glossing in ASL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To gloss American Sign Language (ASL) using Python and SpaCy, you would need to set up a system to process the input text according to the rules of ASL glossing. Below are the basic rules for ASL glossing followed by a Python code example using SpaCy.\n",
    "*** ASL Glossing Rules: ***\n",
    "1. Uppercase Letters: Write each ASL sign in uppercase letters.\\ DONE\n",
    "2. Non-Manual Signals (NMS): Indicate non-manual signals such as facial expressions or body movements above the glossed sign.\\\n",
    "3. Fingerspelling: Represent fingerspelled words with dashes between each letter.\\\n",
    "4. Lexicalized Fingerspelling: Indicate lexicalized fingerspelling with a # symbol.\\\n",
    "5. Repetition: Show repeated signs with a plus sign (+) after the gloss.\\\n",
    "6. Role Shift: Indicate role shift with \"rs\" before the gloss.\\\n",
    "7. Indexing/Pointing: Use \"ix\" followed by a subscript letter or number for indexing.\\\n",
    "8. Directional Signs: Indicate the direction of the sign with arrows or other indicators.\\\n",
    "9. Classifiers: Use abbreviations for classifiers.\\\n",
    "10. Time Indicators: Place time indicators at the beginning of the sentence.\\ DONE\n",
    "11. Topic-Comment Structure: Indicate the topic followed by the comment.\\\n",
    "12. English Words/Concepts: Use English gloss in quotation marks for concepts without direct ASL equivalents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.scorer import Scorer\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from spacy.training.example import Example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CSV Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfile_path = 'Input/ASLG_PC12_train.csv/train.csv'\\ndf = pd.read_csv(file_path)\\n\\nprint(f'df.shape: {df.shape}')\\n\\ndf.columns\\n\""
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "file_path = 'Input/ASLG_PC12_train.csv/train.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(f'df.shape: {df.shape}')\n",
    "\n",
    "df.columns\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Spacy instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SpaCy model\n",
    "## attention de faire: python -m spacy download en_core_web_sm si nÃ©cessaire\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example sentences and their corresponding reference glosses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example sentences and their corresponding reference glosses\n",
    "## list of tuples\n",
    "\"\"\"\n",
    "examples = [\n",
    "    (\"Yesterday, I saw a car and a person.\", \"YESTERDAY I IX_1 SAW CL:3 AND CL:1.\"),\n",
    "    (\"I went to the store.\", \"I IX_1 WENT STORE.\"),\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "# Example sentences\n",
    "examples = [\n",
    "    (\"the high costs of patents in europe , you say , might possibly explain this\",\n",
    "     \"DESC-HIGH COST PATENT IN EUROPE , X-YOU SAY , MIGHT DESC-POSSIBLY EXPLAIN THIS\"),\n",
    "    (\"i should like to congratulate you once again , commissioner , on a fascinating publication\",\n",
    "     \"X-I SHOULD LIKE TO CONGRATULATE X-YOU DESC-ONCE DESC-AGAIN , COMMISSIONER , ON DESC-FASCINATING PUBLICATION\"),\n",
    "    (\"i will also create the post of commissioner for internal affairs and migration , including security\",\n",
    "     \"X-I WILL DESC-ALSO CREATE POST COMMISSIONER FOR DESC-INTERNAL AFFAIR AND MIGRATION , INCLUDE SECURITY\"),\n",
    "    (\"the sitting was suspended at 3.25 p.m. and resumed at 6.00 p.m.\",\n",
    "     \"SIT BE SUSPEND AT 3.25 DESC-P.M. AND RESUME AT 6.00 DESC-P.M.\"),\n",
    "    (\"Where is the bathroom?\",\n",
    "     \"wh WHERE BATHROOM\"),\n",
    "    (\"pl mr president , I would like to thank the rapporteur for her work\",\n",
    "     \"PL MR PRESIDENT , X-I WOULD LIKE TO THANK RAPPORTEUR FOR X-SHE WORK\"),\n",
    "    (\"Do you like coffee ?\",\n",
    "     \"q YOU LIKE COFFEE\"),\n",
    "    (\"I will go to the store tomorrow.\",\n",
    "     \"TOMORROW STORE I GO\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of question adverbs\n",
    "opened_question_adverbs = [\"how\", \"when\", \"where\", \"why\", \"how much\", \"how many\", \"how often\", \"how long\", \"what\", \"which\", \"who\", \"whose\", \"whom\"]\n",
    "\n",
    "time_words = [\"yesterday\", \"today\", \"tomorrow\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASL Gloss standard functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASL glossing rules implemented in functions\n",
    "def gloss_word(word):\n",
    "    return word.upper()\n",
    "\n",
    "def handle_fingerspelling(word):\n",
    "    return '-'.join(list(word.upper()))\n",
    "\n",
    "def handle_lexicalized_fingerspelling(word):\n",
    "    return f\"#{word.upper()}\"\n",
    "\n",
    "def handle_repetition(word, count):\n",
    "    return f\"{word.upper()}{'+' * (count - 1)}\" if count > 1 else word.upper()\n",
    "\n",
    "def handle_role_shift(sentence):\n",
    "    return f\"rs {sentence}\"\n",
    "\n",
    "def handle_indexing(token, index):\n",
    "    return f\"ix_{index} {token.upper()}\"\n",
    "\n",
    "def gloss_sentence(doc):\n",
    "    glossed_sentence = []\n",
    "    for token in doc:\n",
    "        glossed_word = gloss_word(token.text)\n",
    "        glossed_sentence.append(glossed_word)\n",
    "    return \" \".join(glossed_sentence)\n",
    "\n",
    "\"\"\"\n",
    "def add_time_indicator(doc):\n",
    "    glossed_sentence = gloss_sentence(doc)\n",
    "    for word in doc:\n",
    "        if word.text.lower() in time_words:\n",
    "            return f\"{word.text.upper()} {glossed_sentence.replace(word.text.upper(), '').strip()}\"\n",
    "    return glossed_sentence\n",
    "\"\"\"\n",
    "\n",
    "def add_time_indicator(gloss_sentence_):\n",
    "    for word in gloss_sentence_:\n",
    "        if word.text.lower() in time_words:\n",
    "            return f\"{word.text.upper()} {gloss_sentence_.replace(word.text.upper(), '').strip()}\"\n",
    "    return gloss_sentence_\n",
    "\n",
    "## skip stop_words\n",
    "def skip_stop_words(word):\n",
    "    if word.lower() == 'the' or word.lower() == 'a':\n",
    "        return ''\n",
    "    else:\n",
    "        return word\n",
    "\n",
    "## doc est une liste de tokens\n",
    "def question_type(doc):\n",
    "    if doc[-1].text == '?':\n",
    "        if doc[0].text.lower() in opened_question_adverbs:\n",
    "            return \"wh-question\"\n",
    "        else:\n",
    "            return \"yes-no-question\"\n",
    "    return None\n",
    "\n",
    "# add question id as a prefix\n",
    "def process_sentence(doc):\n",
    "    nms = {\n",
    "        \"wh-question\": \"wh-q\",\n",
    "        \"yes-no-question\": \"y/n-q\"\n",
    "    }\n",
    "    \n",
    "    classifiers = {\n",
    "        \"car\": \"CL:3\",\n",
    "        \"person\": \"CL:1\"\n",
    "    }\n",
    "    \n",
    "    glossed_sentence = []\n",
    "    for token in doc:\n",
    "        ## utilize token.lemma_, not .text\n",
    "        #word = token.text.lower()\n",
    "        word = token.lemma_.lower()\n",
    "        \n",
    "        if word in [\"i\", \"me\"]:\n",
    "            glossed_word = handle_indexing(\"I\", 1)\n",
    "        elif word in [\"you\"]:\n",
    "            glossed_word = handle_indexing(\"YOU\", 2)\n",
    "        elif word in classifiers:\n",
    "            glossed_word = classifiers[word]\n",
    "        else:\n",
    "            glossed_word = gloss_word(word)\n",
    "        glossed_word = skip_stop_words(glossed_word)\n",
    "        \n",
    "        glossed_sentence.append(glossed_word)    \n",
    "\n",
    "    for gloss in glossed_sentence:\n",
    "        if gloss.lower() in time_words:\n",
    "            print(f'gloss: {gloss}')\n",
    "            # move gloss at beginning\n",
    "            glossed_sentence.insert(0, glossed_sentence.pop(glossed_sentence.index(gloss)))\n",
    "            break\n",
    "          \n",
    "    type_doc = question_type(doc)\n",
    "    if type_doc != None:\n",
    "        glossed_sentence.insert(0, nms[type_doc])\n",
    "        \n",
    "    return \" \".join(glossed_sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "NB: deterministic model = set of ASL-Gloss-rules functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate_glossing(examples):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    for sentence, reference_gloss in examples:\n",
    "        doc = nlp(sentence)\n",
    "        generated_gloss = process_sentence(doc) ## deterministic model = set of ASL-Gloss-rules functions\n",
    "        \n",
    "        # Tokenize glosses for comparison\n",
    "        reference_tokens = reference_gloss.split()\n",
    "        generated_tokens = generated_gloss.split()\n",
    "        \n",
    "        y_true.extend([reference_tokens])\n",
    "        y_pred.extend([generated_tokens])\n",
    "        \n",
    "    return y_true, y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten the lists for sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "def compute_metrics(y_true_, y_pred_):\n",
    "    precision = precision_score(y_true_, y_pred_, average='weighted', zero_division=1)\n",
    "    recall = recall_score(y_true_, y_pred_, average='weighted', zero_division=1)\n",
    "    f1 = f1_score(y_true_, y_pred_, average='weighted', zero_division=1)\n",
    "\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "    return {\"precision\": precision, \"recall\": recall, \"f1_score\": f1}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gloss: TOMORROW\n",
      "<class 'list'>\n",
      "sentence: the high costs of patents in europe , you say , might possibly explain this\n",
      "y_true sentence: DESC-HIGH COST PATENT IN EUROPE , X-YOU SAY , MIGHT DESC-POSSIBLY EXPLAIN THIS\n",
      "y_pred sentence: HIGH COST OF PATENT IN EUROPE , ix_2 YOU SAY , MIGHT POSSIBLY EXPLAIN THIS\n",
      "sentence: i should like to congratulate you once again , commissioner , on a fascinating publication\n",
      "y_true sentence: X-I SHOULD LIKE TO CONGRATULATE X-YOU DESC-ONCE DESC-AGAIN , COMMISSIONER , ON DESC-FASCINATING PUBLICATION\n",
      "y_pred sentence: ix_1 I SHOULD LIKE TO CONGRATULATE ix_2 YOU ONCE AGAIN , COMMISSIONER , ON FASCINATING PUBLICATION\n",
      "sentence: i will also create the post of commissioner for internal affairs and migration , including security\n",
      "y_true sentence: X-I WILL DESC-ALSO CREATE POST COMMISSIONER FOR DESC-INTERNAL AFFAIR AND MIGRATION , INCLUDE SECURITY\n",
      "y_pred sentence: ix_1 I WILL ALSO CREATE POST OF COMMISSIONER FOR INTERNAL AFFAIR AND MIGRATION , INCLUDE SECURITY\n",
      "sentence: the sitting was suspended at 3.25 p.m. and resumed at 6.00 p.m.\n",
      "y_true sentence: SIT BE SUSPEND AT 3.25 DESC-P.M. AND RESUME AT 6.00 DESC-P.M.\n",
      "y_pred sentence: SITTING BE SUSPEND AT 3.25 P.M. AND RESUME AT 6.00 P.M.\n",
      "sentence: Where is the bathroom?\n",
      "y_true sentence: wh WHERE BATHROOM\n",
      "y_pred sentence: wh-q WHERE BE BATHROOM ?\n",
      "sentence: pl mr president , I would like to thank the rapporteur for her work\n",
      "y_true sentence: PL MR PRESIDENT , X-I WOULD LIKE TO THANK RAPPORTEUR FOR X-SHE WORK\n",
      "y_pred sentence: PL MR PRESIDENT , ix_1 I WOULD LIKE TO THANK RAPPORTEUR FOR HER WORK\n",
      "sentence: Do you like coffee ?\n",
      "y_true sentence: q YOU LIKE COFFEE\n",
      "y_pred sentence: y/n-q DO ix_2 YOU LIKE COFFEE ?\n",
      "sentence: I will go to the store tomorrow.\n",
      "y_true sentence: TOMORROW STORE I GO\n",
      "y_pred sentence: TOMORROW ix_1 I WILL GO TO STORE .\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "y_true, y_pred = evaluate_glossing(examples)\n",
    "\n",
    "print(type(y_true))\n",
    "\n",
    "for idx, sentence in enumerate(examples):\n",
    "    print(f'sentence: {sentence[0]}')\n",
    "    print(f'y_true sentence: {\" \".join(y_true[idx])}')\n",
    "    print(f'y_pred sentence: {\" \".join(y_pred[idx])}')\n",
    "\n",
    "###precision, recall, f1_score = compute_metrics(y_pred, y_pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv4",
   "language": "python",
   "name": ".venv4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
